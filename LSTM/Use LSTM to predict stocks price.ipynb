{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open      High        Low      Close       Volume\n",
      "Date                                                              \n",
      "2022-07-01  107.93300  109.2500  106.73000  108.73800   35475660.0\n",
      "2022-06-30  110.00000  110.8880  106.75000  108.96300   43169060.0\n",
      "2022-06-29  111.55200  113.1600  110.87300  111.70200   24716820.0\n",
      "2022-06-28  115.80300  117.3100  111.84800  112.00800   35880960.0\n",
      "2022-06-27  118.27300  118.5800  115.18000  115.83400   36420760.0\n",
      "...               ...       ...        ...        ...          ...\n",
      "2004-08-25    2.62400    2.7000    2.59700    2.65000  183956000.0\n",
      "2004-08-24    2.78100    2.7900    2.58925    2.62175  305252000.0\n",
      "2004-08-23    2.76875    2.8370    2.72625    2.73500  365488000.0\n",
      "2004-08-20    2.52525    2.7270    2.51250    2.70775  457144000.0\n",
      "2004-08-19    2.50000    2.6015    2.39900    2.50850  894076000.0\n",
      "\n",
      "[4499 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2000, 1, 1)\n",
    "end = datetime.datetime(2022, 7, 1)\n",
    "df = web.DataReader('GOOGL', 'stooq', start, end)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#删掉空值\n",
    "def Stock_Price_LSTM_Data_Processing(df,mem_his_days,pre_days):\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    #label 将收盘价作为label  预测未来10天，将收盘价的这一列拿到做label，往上移动10天的数据 用前十天来预测\n",
    "    #pre_days = 10\n",
    "    df['label'] = df['Close'].shift(-pre_days)#拿来做预测\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    #选用所有的行，取到最后的列label  这一步是进行标准化工作\n",
    "    scaler = StandardScaler()\n",
    "    sca_X = scaler.fit_transform(df.iloc[:,:-1])\n",
    "    #print(sca_X)\n",
    "    #mem_his_days = 10\n",
    "    from collections import deque\n",
    "    deq = deque(maxlen=mem_his_days)\n",
    "\n",
    "    X = []\n",
    "    for i in sca_X:\n",
    "        deq.append(list(i))\n",
    "        if len(deq)==mem_his_days:\n",
    "            X.append(list(deq))\n",
    "\n",
    "    X_lately = X[-pre_days:]\n",
    "    X = X[:-pre_days]\n",
    "   # print(len(X))#每一个deq里有5个，X最后将其全部append了\n",
    "    #print(X)\n",
    "    #print(len(X_lately))\n",
    "\n",
    "    y = df['label'].values[mem_his_days-1:-pre_days]#TODO: -1有一点点疑惑，以后懂了再解决\n",
    "    #print(len(y))\n",
    "    import numpy as np\n",
    "    X = np.array(X)\n",
    "    y =np.array(y)\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    return X,y,X_lately"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X,y,X_lately = Stock_Price_LSTM_Data_Processing(df,10,10)\n",
    "print(X[0][1])\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#优化一些模型，回溯 5 10 15天进行尝试 创造一些list\n",
    "#创造一些lstm的记忆层，1,2,3,层\n",
    "#dense  层 3层 时间运行长短的问题\n",
    "#units 神经元每层有多少个\n",
    "# 利用checkpoint设立检查点\n",
    "pre_days = 10\n",
    "mem_days = [5,10,15]\n",
    "lstm_layers = [1,2,3]\n",
    "dense_layers = [1,2,3]\n",
    "units = [16,32]\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "for the_mem_day in mem_days:\n",
    "    for the_lstm_layer in lstm_layers:\n",
    "        for the_dense_layer in dense_layers:\n",
    "            for the_unit in units:\n",
    "                filepath = './models/{val_mape:.2f}_{epoch:02d}_'+f'mem_{the_mem_day}_lstm_{the_lstm_layer}_dense_{the_dense_layer}_unit_{the_unit}'\n",
    "                checkpoint = ModelCheckpoint(\n",
    "                    filepath = filepath,\n",
    "                    save_wieights_only=False,\n",
    "                    monitor='val_mape',\n",
    "                    mode='min',\n",
    "                    save_bests_only=True\n",
    "                )\n",
    "                X,y,X_lately = Stock_Price_LSTM_Data_Processing(df,the_mem_day,pre_days)\n",
    "                from sklearn.model_selection import train_test_split\n",
    "                X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)\n",
    "                #开始用tf进行预测了\n",
    "                import tensorflow.keras as tf\n",
    "                from tensorflow.keras.models import Sequential #引入神经网络中的层 dropout 删除一些值\n",
    "                from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(LSTM(the_unit,input_shape=X.shape[1:],activation='relu',return_sequences=True))#1: 有点疑惑\n",
    "                model.add(Dropout(0.1))\n",
    "                for i in range(the_lstm_layer):\n",
    "\n",
    "                    model.add(LSTM(the_unit,activation='relu',return_sequences=True))\n",
    "                    model.add(Dropout(0.1))\n",
    "                model.add(LSTM(the_unit,activation='relu'))\n",
    "                model.add(Dropout(0.1))\n",
    "                #10个神经单元 input_shape为X  等下会划分一下 防止过拟合，就删除一些神经元\n",
    "                #可以构建一个全连接层，激活函数也是relu Dense \n",
    "                #做编译，有三个，优化器，损失函数，评价函数\n",
    "                for i in range(the_dense_layer):\n",
    "\n",
    "                    model.add(Dense(the_unit,activation='relu'))\n",
    "                    model.add(Dropout(0.1))\n",
    "                model.add(Dense(1))\n",
    "\n",
    "                model.compile(optimizer='adam',\n",
    "                             loss='mse',\n",
    "                             metrics=['mape'])\n",
    "\n",
    "\n",
    "                #开始训练\n",
    "                model.fit(X_train,y_train,batch_size=32,epochs=50,validation_data=(X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#选用所有的行，取到最后的列label  这一步是进行标准化工作\n",
    "scaler = StandardScaler()\n",
    "sca_X = scaler.fit_transform(df.iloc[:,:-1])\n",
    "print(sca_X)\n",
    "#损失是累加不是单词训练的结果，而是这一轮次内的\n",
    "#实际的 x y test\n",
    "#预测的predict\n",
    "# best_model.evaluate(X_test,y_test)#实际\n",
    "pre = best_model.predict(X_test)#预测"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4454, 5, 5)\n",
      "(4454,)\n",
      "Epoch 1/50\n",
      "126/126 [==============================] - 4s 9ms/step - loss: 1671.1182 - mape: 86.1598 - val_loss: 166.9499 - val_mape: 42.5871\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 167.0445 - mape: 29.0512 - val_loss: 36.5618 - val_mape: 16.3970\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 134.2350 - mape: 23.6588 - val_loss: 20.6168 - val_mape: 12.6578\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 109.3175 - mape: 22.3880 - val_loss: 11.0091 - val_mape: 11.5351\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 114.9677 - mape: 21.3370 - val_loss: 8.6953 - val_mape: 9.9254\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 113.9086 - mape: 20.5728 - val_loss: 14.1520 - val_mape: 9.9862\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 105.5601 - mape: 19.7325 - val_loss: 10.6156 - val_mape: 8.6401\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 94.9089 - mape: 18.4997 - val_loss: 37.5038 - val_mape: 11.6720\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 83.0369 - mape: 17.9785 - val_loss: 54.8969 - val_mape: 13.1515\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 95.0980 - mape: 17.3738 - val_loss: 61.2083 - val_mape: 11.9604\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 85.0012 - mape: 17.6178 - val_loss: 16.6523 - val_mape: 7.3613\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 88.0059 - mape: 17.0883 - val_loss: 9.6043 - val_mape: 6.5757\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 84.1764 - mape: 16.3820 - val_loss: 58.4427 - val_mape: 10.2511\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 84.8178 - mape: 16.5165 - val_loss: 41.3321 - val_mape: 8.1606\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 76.8199 - mape: 16.0464 - val_loss: 14.0736 - val_mape: 5.7391\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 75.4410 - mape: 15.9535 - val_loss: 35.5193 - val_mape: 8.2185\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 73.8700 - mape: 15.7849 - val_loss: 21.6529 - val_mape: 9.3564\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 73.6194 - mape: 15.7586 - val_loss: 22.1821 - val_mape: 9.0863\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 70.0569 - mape: 14.9798 - val_loss: 47.9538 - val_mape: 11.5386\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 61.2544 - mape: 15.0784 - val_loss: 24.7264 - val_mape: 8.3423\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 68.0086 - mape: 14.7849 - val_loss: 31.4955 - val_mape: 8.3701\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 71.2074 - mape: 14.8504 - val_loss: 16.0551 - val_mape: 5.9523\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 66.5670 - mape: 14.6799 - val_loss: 36.8563 - val_mape: 9.1697\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 73.5533 - mape: 14.5126 - val_loss: 17.0497 - val_mape: 9.6020\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 61.9812 - mape: 14.1135 - val_loss: 29.0703 - val_mape: 10.2429\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 71.4490 - mape: 14.5103 - val_loss: 10.7209 - val_mape: 5.8216\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 62.4277 - mape: 14.0701 - val_loss: 69.4761 - val_mape: 10.1820\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 59.2261 - mape: 14.2620 - val_loss: 17.4589 - val_mape: 5.8003\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 64.0594 - mape: 14.4387 - val_loss: 25.3839 - val_mape: 10.2348\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 63.5520 - mape: 13.8374 - val_loss: 38.5293 - val_mape: 6.7870\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 64.8142 - mape: 14.3303 - val_loss: 18.8216 - val_mape: 11.9413\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 61.3946 - mape: 14.0617 - val_loss: 18.1970 - val_mape: 6.7122\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 60.7958 - mape: 13.5711 - val_loss: 19.6162 - val_mape: 6.5323\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 63.9892 - mape: 13.7200 - val_loss: 29.7723 - val_mape: 6.8767\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 62.1870 - mape: 14.0070 - val_loss: 36.6893 - val_mape: 7.2392\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 56.9795 - mape: 13.4604 - val_loss: 33.8606 - val_mape: 8.5780\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 64.0149 - mape: 13.1484 - val_loss: 36.1392 - val_mape: 7.0514\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 61.5949 - mape: 13.1190 - val_loss: 24.9269 - val_mape: 6.9330\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 62.9559 - mape: 12.9363 - val_loss: 18.8514 - val_mape: 6.3128\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 61.8901 - mape: 13.8012 - val_loss: 28.8870 - val_mape: 10.5439\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 58.0368 - mape: 13.4634 - val_loss: 29.8895 - val_mape: 7.9635\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 62.0665 - mape: 12.8516 - val_loss: 40.4507 - val_mape: 8.2243\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 59.9832 - mape: 12.9066 - val_loss: 31.3022 - val_mape: 8.0324\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 64.0978 - mape: 13.2312 - val_loss: 46.5869 - val_mape: 10.3657\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 60.5087 - mape: 13.2625 - val_loss: 78.8077 - val_mape: 9.4488\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 53.8250 - mape: 12.8829 - val_loss: 47.5444 - val_mape: 9.5838\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 64.6339 - mape: 13.0037 - val_loss: 56.0892 - val_mape: 11.8872\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 57.0739 - mape: 13.2147 - val_loss: 35.3461 - val_mape: 8.6943\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 57.2584 - mape: 12.5387 - val_loss: 27.3374 - val_mape: 10.3943\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 1s 6ms/step - loss: 60.1497 - mape: 13.1189 - val_loss: 60.5647 - val_mape: 10.2783\n",
      "(4444, 5, 5)\n",
      "(4444,)\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 4s 10ms/step - loss: 1089.0280 - mape: 64.3323 - val_loss: 40.2496 - val_mape: 17.5785\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 80.3400 - mape: 22.8855 - val_loss: 27.2403 - val_mape: 16.0322\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 66.1267 - mape: 20.9375 - val_loss: 15.6137 - val_mape: 12.1153\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 66.5390 - mape: 18.3085 - val_loss: 14.2609 - val_mape: 13.9502\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 62.3089 - mape: 17.3475 - val_loss: 9.8229 - val_mape: 7.9050\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 54.1072 - mape: 16.1095 - val_loss: 10.8502 - val_mape: 7.8072\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 45.1734 - mape: 15.2441 - val_loss: 9.6459 - val_mape: 7.8697\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 42.3016 - mape: 14.7996 - val_loss: 9.8495 - val_mape: 7.3062\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 48.6990 - mape: 14.9634 - val_loss: 8.7817 - val_mape: 6.4972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 44.5846 - mape: 14.2341 - val_loss: 11.6744 - val_mape: 7.8756\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 44.3907 - mape: 13.4976 - val_loss: 8.8312 - val_mape: 7.5474\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 47.5259 - mape: 13.9414 - val_loss: 17.0353 - val_mape: 10.2882\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 41.2759 - mape: 12.7131 - val_loss: 15.4845 - val_mape: 8.1339\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 38.9883 - mape: 12.9321 - val_loss: 9.4600 - val_mape: 6.5530\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 38.9662 - mape: 12.6303 - val_loss: 9.6015 - val_mape: 7.6794\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 44.9777 - mape: 14.1668 - val_loss: 14.9288 - val_mape: 7.2088\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 37.2099 - mape: 12.5548 - val_loss: 11.5405 - val_mape: 6.9353\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 38.5116 - mape: 12.4852 - val_loss: 8.5838 - val_mape: 7.6183\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 36.9267 - mape: 12.3363 - val_loss: 10.3957 - val_mape: 6.7216\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 37.7757 - mape: 11.9952 - val_loss: 19.7504 - val_mape: 7.4347\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 36.7229 - mape: 12.2423 - val_loss: 9.0078 - val_mape: 5.5854\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 41.6633 - mape: 12.5651 - val_loss: 15.7088 - val_mape: 8.4827\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 37.5463 - mape: 11.9450 - val_loss: 11.1004 - val_mape: 6.4840\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 42.2385 - mape: 12.2752 - val_loss: 8.6334 - val_mape: 5.7214\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 37.3742 - mape: 11.7265 - val_loss: 12.8226 - val_mape: 10.9592\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 38.1884 - mape: 11.6730 - val_loss: 9.2551 - val_mape: 6.9755\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 41.8762 - mape: 11.9865 - val_loss: 18.5213 - val_mape: 8.4399\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 36.2881 - mape: 11.9347 - val_loss: 9.1381 - val_mape: 6.1304\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 37.7819 - mape: 11.5713 - val_loss: 7.9961 - val_mape: 5.9143\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 41.0946 - mape: 11.7402 - val_loss: 13.9039 - val_mape: 6.1682\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 36.7765 - mape: 11.8472 - val_loss: 17.6822 - val_mape: 9.1328\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 40.1767 - mape: 12.0446 - val_loss: 13.3674 - val_mape: 8.9763\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 38.8928 - mape: 11.8223 - val_loss: 23.8982 - val_mape: 8.8612\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 37.3328 - mape: 11.7938 - val_loss: 11.0406 - val_mape: 7.1514\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 35.6405 - mape: 11.3024 - val_loss: 8.3853 - val_mape: 6.0793\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 36.3964 - mape: 11.5503 - val_loss: 12.9275 - val_mape: 6.1369\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 32.3822 - mape: 11.0007 - val_loss: 19.1245 - val_mape: 7.3680\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 46.6264 - mape: 11.7809 - val_loss: 17.9435 - val_mape: 6.9184\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 41.3763 - mape: 11.1544 - val_loss: 23.2644 - val_mape: 8.8139\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 37.6771 - mape: 11.4524 - val_loss: 10.8045 - val_mape: 7.1573\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 39.1479 - mape: 11.5799 - val_loss: 9.3688 - val_mape: 6.3650\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 34.2924 - mape: 11.3893 - val_loss: 10.6668 - val_mape: 6.5737\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 35.0968 - mape: 11.1017 - val_loss: 8.7826 - val_mape: 8.2711\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 31.6915 - mape: 10.9153 - val_loss: 8.6335 - val_mape: 5.8217\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 38.1135 - mape: 11.0208 - val_loss: 10.6074 - val_mape: 7.6958\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 32.2687 - mape: 10.9496 - val_loss: 24.8573 - val_mape: 7.2500\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 39.2260 - mape: 11.0280 - val_loss: 7.8321 - val_mape: 5.9191\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 36.2687 - mape: 11.0035 - val_loss: 8.7375 - val_mape: 7.6118\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 37.2256 - mape: 10.6591 - val_loss: 20.1037 - val_mape: 9.4038\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 35.1945 - mape: 10.7529 - val_loss: 17.2494 - val_mape: 6.8600\n",
      "(4434, 5, 5)\n",
      "(4434,)\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 4s 12ms/step - loss: 1655.9478 - mape: 87.4493 - val_loss: 155.0694 - val_mape: 50.8262\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 185.9969 - mape: 33.8975 - val_loss: 122.0343 - val_mape: 22.2565\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 155.2548 - mape: 25.2003 - val_loss: 85.5004 - val_mape: 17.7393\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 119.0085 - mape: 22.0225 - val_loss: 30.9511 - val_mape: 13.0604\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 105.8069 - mape: 21.2398 - val_loss: 23.9312 - val_mape: 11.8110\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 104.7614 - mape: 20.7804 - val_loss: 60.0651 - val_mape: 14.9658\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 95.8003 - mape: 19.9297 - val_loss: 70.6538 - val_mape: 11.9355\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 86.5162 - mape: 18.6290 - val_loss: 56.7913 - val_mape: 13.3780\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 71.8933 - mape: 17.6726 - val_loss: 62.5006 - val_mape: 14.2822\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 76.2526 - mape: 16.9791 - val_loss: 60.2124 - val_mape: 11.8730\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 66.0285 - mape: 16.6649 - val_loss: 75.0233 - val_mape: 13.8432\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 68.6031 - mape: 17.2432 - val_loss: 144.3580 - val_mape: 20.2059\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 69.8537 - mape: 16.2916 - val_loss: 99.3915 - val_mape: 14.9817\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 60.4634 - mape: 15.4725 - val_loss: 63.7600 - val_mape: 13.1992\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 62.3127 - mape: 15.2510 - val_loss: 90.5552 - val_mape: 13.2484\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 59.7325 - mape: 14.9476 - val_loss: 158.4545 - val_mape: 19.3769\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 60.5471 - mape: 14.7778 - val_loss: 40.6944 - val_mape: 10.3394\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 59.0283 - mape: 14.8177 - val_loss: 82.0930 - val_mape: 12.2915\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 7ms/step - loss: 55.6827 - mape: 14.6383 - val_loss: 112.4550 - val_mape: 13.8106\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 57.4211 - mape: 14.0594 - val_loss: 85.5130 - val_mape: 12.7579\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 53.6924 - mape: 14.2811 - val_loss: 128.1158 - val_mape: 17.3690\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 59.1733 - mape: 14.3010 - val_loss: 78.2482 - val_mape: 10.5436\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 56.6856 - mape: 13.7527 - val_loss: 132.6992 - val_mape: 15.4426\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 56.7639 - mape: 14.1786 - val_loss: 60.0333 - val_mape: 10.6929\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 46.8609 - mape: 13.7605 - val_loss: 73.5269 - val_mape: 11.5360\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 48.2558 - mape: 13.5270 - val_loss: 76.0926 - val_mape: 12.1255\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 48.0936 - mape: 13.4808 - val_loss: 110.5687 - val_mape: 12.9930\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 57.7451 - mape: 13.4649 - val_loss: 106.0302 - val_mape: 13.1088\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 53.0693 - mape: 13.2663 - val_loss: 116.7740 - val_mape: 15.5936\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 54.5034 - mape: 12.7292 - val_loss: 95.9362 - val_mape: 14.5183\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 49.7681 - mape: 12.9849 - val_loss: 104.9192 - val_mape: 14.9106\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 52.8096 - mape: 13.0707 - val_loss: 155.8040 - val_mape: 17.0065\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 45.9959 - mape: 12.8133 - val_loss: 82.4265 - val_mape: 11.2079\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 48.0664 - mape: 12.7215 - val_loss: 92.6281 - val_mape: 11.7402\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 47.2251 - mape: 12.3788 - val_loss: 112.8282 - val_mape: 15.2414\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 44.9461 - mape: 12.1153 - val_loss: 87.6142 - val_mape: 13.1320\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 43.8231 - mape: 12.1751 - val_loss: 71.1833 - val_mape: 13.4703\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 47.0284 - mape: 12.5732 - val_loss: 164.8906 - val_mape: 18.7358\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 49.3369 - mape: 12.5135 - val_loss: 111.4255 - val_mape: 14.9404\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 45.8430 - mape: 12.3910 - val_loss: 116.3753 - val_mape: 16.0506\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 45.2327 - mape: 11.9564 - val_loss: 145.8936 - val_mape: 15.7978\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 46.8847 - mape: 12.1074 - val_loss: 86.0123 - val_mape: 14.5285\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 48.1647 - mape: 12.2091 - val_loss: 86.7560 - val_mape: 12.4669\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 46.6187 - mape: 11.4737 - val_loss: 83.5598 - val_mape: 11.6380\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 42.0015 - mape: 11.7395 - val_loss: 140.3527 - val_mape: 17.1674\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 45.6056 - mape: 11.4849 - val_loss: 108.0431 - val_mape: 14.3116\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 46.1002 - mape: 12.2209 - val_loss: 166.7738 - val_mape: 18.2415\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 45.4836 - mape: 11.7463 - val_loss: 95.6788 - val_mape: 15.5495\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 41.5564 - mape: 11.6049 - val_loss: 110.5805 - val_mape: 13.7267\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 47.1860 - mape: 11.6903 - val_loss: 100.6941 - val_mape: 12.3317\n",
      "(4424, 5, 5)\n",
      "(4424,)\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 4s 11ms/step - loss: 1117.3253 - mape: 66.7029 - val_loss: 44.8277 - val_mape: 21.5786\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 111.1707 - mape: 24.7525 - val_loss: 14.2912 - val_mape: 17.6518\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 86.9446 - mape: 21.3380 - val_loss: 12.1451 - val_mape: 12.7129\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 75.0918 - mape: 18.6729 - val_loss: 12.0757 - val_mape: 9.9882\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 77.1204 - mape: 17.3065 - val_loss: 12.0132 - val_mape: 12.5090\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 69.2570 - mape: 16.6322 - val_loss: 15.0892 - val_mape: 8.3547\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 62.1502 - mape: 15.0315 - val_loss: 6.5118 - val_mape: 7.4694\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 59.2794 - mape: 15.4155 - val_loss: 6.5954 - val_mape: 7.4188\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 53.6737 - mape: 14.9378 - val_loss: 27.2044 - val_mape: 10.3319\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 56.3464 - mape: 14.6519 - val_loss: 40.3545 - val_mape: 9.1576\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 54.8666 - mape: 14.8535 - val_loss: 24.9866 - val_mape: 10.9632\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 54.5139 - mape: 14.3067 - val_loss: 52.6325 - val_mape: 11.5824\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 62.3359 - mape: 14.9811 - val_loss: 12.7953 - val_mape: 7.9559\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 50.2054 - mape: 13.2998 - val_loss: 16.4584 - val_mape: 7.2829\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 52.2713 - mape: 13.7040 - val_loss: 20.1031 - val_mape: 7.6994\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 52.7800 - mape: 13.7362 - val_loss: 22.0274 - val_mape: 9.2453\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 49.7445 - mape: 13.4387 - val_loss: 21.9405 - val_mape: 6.9628\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 50.6611 - mape: 12.9981 - val_loss: 27.3562 - val_mape: 7.7512\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 47.7898 - mape: 13.1344 - val_loss: 45.3482 - val_mape: 11.0269\n",
      "Epoch 20/50\n",
      "  6/125 [>.............................] - ETA: 1s - loss: 51.8761 - mape: 12.9817"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [28]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     50\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     51\u001B[0m              loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmse\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     52\u001B[0m              metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmape\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m#开始训练\u001B[39;00m\n\u001B[1;32m---> 56\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Graduate_Tasks\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32mE:\\Graduate_Tasks\\venv\\lib\\site-packages\\keras\\engine\\training.py:1208\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1206\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch)\n\u001B[0;32m   1207\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[1;32m-> 1208\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[0;32m   1209\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1210\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1211\u001B[0m         epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1212\u001B[0m         step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1213\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1214\u001B[0m         _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1215\u001B[0m       callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n",
      "File \u001B[1;32mE:\\Graduate_Tasks\\venv\\lib\\site-packages\\keras\\engine\\data_adapter.py:1250\u001B[0m, in \u001B[0;36mDataHandler.steps\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1248\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n\u001B[0;32m   1249\u001B[0m   \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1250\u001B[0m original_spe \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m   1251\u001B[0m can_run_full_execution \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1252\u001B[0m     original_spe \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1253\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1254\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m\n\u001B[0;32m   1255\u001B[0m     original_spe)\n\u001B[0;32m   1257\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m can_run_full_execution:\n",
      "File \u001B[1;32mE:\\Graduate_Tasks\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:645\u001B[0m, in \u001B[0;36mBaseResourceVariable.numpy\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    643\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnumpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    644\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 645\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    646\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    647\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy() is only available when eager execution is enabled.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\Graduate_Tasks\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:720\u001B[0m, in \u001B[0;36mBaseResourceVariable.read_value\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001B[39;00m\n\u001B[0;32m    712\u001B[0m \n\u001B[0;32m    713\u001B[0m \u001B[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    717\u001B[0m \u001B[38;5;124;03m the read operation.\u001B[39;00m\n\u001B[0;32m    718\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    719\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mname_scope(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRead\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 720\u001B[0m   value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_variable_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    721\u001B[0m \u001B[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001B[39;00m\n\u001B[0;32m    722\u001B[0m \u001B[38;5;66;03m# specifies instead of the device where the variable is.\u001B[39;00m\n\u001B[0;32m    723\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m array_ops\u001B[38;5;241m.\u001B[39midentity(value)\n",
      "File \u001B[1;32mE:\\Graduate_Tasks\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:699\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    697\u001B[0m       result \u001B[38;5;241m=\u001B[39m read_and_set_handle()\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 699\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mread_and_set_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    701\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m    702\u001B[0m   \u001B[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001B[39;00m\n\u001B[0;32m    703\u001B[0m   \u001B[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001B[39;00m\n\u001B[0;32m    704\u001B[0m   tape\u001B[38;5;241m.\u001B[39mrecord_operation(\n\u001B[0;32m    705\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReadVariableOp\u001B[39m\u001B[38;5;124m\"\u001B[39m, [result], [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle],\n\u001B[0;32m    706\u001B[0m       backward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x],\n\u001B[0;32m    707\u001B[0m       forward_function\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: [x])\n",
      "File \u001B[1;32mE:\\Graduate_Tasks\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001B[0m, in \u001B[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001B[1;34m()\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_and_set_handle\u001B[39m():\n\u001B[1;32m--> 689\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[43mgen_resource_variable_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_variable_op\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    691\u001B[0m   _maybe_set_handle_data(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dtype, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle, result)\n\u001B[0;32m    692\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mE:\\Graduate_Tasks\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:469\u001B[0m, in \u001B[0;36mread_variable_op\u001B[1;34m(resource, dtype, name)\u001B[0m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m    468\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 469\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    470\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mReadVariableOp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdtype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    471\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m    472\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#优化一些模型，回溯 5 10 15天进行尝试 创造一些list\n",
    "#创造一些lstm的记忆层，1,2,3,层\n",
    "#dense  层 3层 时间运行长短的问题\n",
    "#units 神经元每层有多少个\n",
    "# 利用checkpoint设立检查点\n",
    "pre_days = 10\n",
    "mem_days = [5,10,15]\n",
    "lstm_layers = [1,2,3]\n",
    "dense_layers = [1,2,3]\n",
    "units = [16,32]\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "for the_mem_day in mem_days:\n",
    "    for the_lstm_layer in lstm_layers:\n",
    "        for the_dense_layer in dense_layers:\n",
    "            for the_unit in units:\n",
    "                filepath = './models/{val_mape:.2f}_{epoch:02d}_'+f'mem_{the_mem_day}_lstm_{the_lstm_layer}_dense_{the_dense_layer}_unit_{the_unit}'\n",
    "                checkpoint = ModelCheckpoint(\n",
    "                    filepath = filepath,\n",
    "                    save_wieights_only=False,\n",
    "                    monitor='val_mape',\n",
    "                    mode='min',\n",
    "                    save_bests_only=True\n",
    "                )\n",
    "                X,y,X_lately = Stock_Price_LSTM_Data_Processing(df,the_mem_day,pre_days)\n",
    "                from sklearn.model_selection import train_test_split\n",
    "                X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)\n",
    "                #开始用tf进行预测了\n",
    "                import tensorflow.keras as tf\n",
    "                from tensorflow.keras.models import Sequential #引入神经网络中的层 dropout 删除一些值\n",
    "                from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(LSTM(the_unit,input_shape=X.shape[1:],activation='relu',return_sequences=True))#1: 有点疑惑\n",
    "                model.add(Dropout(0.1))\n",
    "                for i in range(the_lstm_layer):\n",
    "\n",
    "                    model.add(LSTM(the_unit,activation='relu',return_sequences=True))\n",
    "                    model.add(Dropout(0.1))\n",
    "                model.add(LSTM(the_unit,activation='relu'))\n",
    "                model.add(Dropout(0.1))\n",
    "                #10个神经单元 input_shape为X  等下会划分一下 防止过拟合，就删除一些神经元\n",
    "                #可以构建一个全连接层，激活函数也是relu Dense \n",
    "                #做编译，有三个，优化器，损失函数，评价函数\n",
    "                for i in range(the_dense_layer):\n",
    "\n",
    "                    model.add(Dense(the_unit,activation='relu'))\n",
    "                    model.add(Dropout(0.1))\n",
    "                model.add(Dense(1))\n",
    "\n",
    "                model.compile(optimizer='adam',\n",
    "                             loss='mse',\n",
    "                             metrics=['mape'])\n",
    "\n",
    "\n",
    "                #开始训练\n",
    "                model.fit(X_train,y_train,batch_size=32,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99286506 -0.99027401 -0.99559177 -0.99272414  4.99923362]\n",
      " [-0.99211526 -0.9865848  -0.99218442 -0.98680629  2.15136524]\n",
      " [-0.9848845  -0.98335122 -0.98576749 -0.98599695  1.55396284]\n",
      " ...\n",
      " [ 2.24544951  2.25971665  2.26087514  2.2503912  -0.66714129]\n",
      " [ 2.19936265  2.19292867  2.13709973  2.16904118 -0.54687189]\n",
      " [ 2.13798279  2.14477783  2.13649932  2.16235854 -0.59701651]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#选用所有的行，取到最后的列label  这一步是进行标准化工作\n",
    "scaler = StandardScaler()\n",
    "sca_X = scaler.fit_transform(df.iloc[:,:-1])\n",
    "print(sca_X)\n",
    "#损失是累加不是单词训练的结果，而是这一轮次内的\n",
    "#实际的 x y test\n",
    "#预测的predict\n",
    "# best_model.evaluate(X_test,y_test)#实际\n",
    "pre = best_model.predict(X_test)#预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4479\n",
      "10\n",
      "4479\n"
     ]
    }
   ],
   "source": [
    "#设置记忆的天数，假设记忆5天\n",
    "#设置一个先进先出的队列  使得其等于要记忆的天数\n",
    "#把deq append一下，当len长度为要记忆的天数的时候，那就append一个deq，超过30天，就先进先出\n",
    "#把最后几条记录一下，跟pre_days有关系的那几条\n",
    "\n",
    "#mem_his_days是打包5天的数据，跟预测多少天后没有关系，y要与X齐平所以要先砍掉；pre_days是预测多少天后的股票价格，y前面label值shift(-pre_days)后，\n",
    "#最后pre_days是空值（你自己打印出来看一下），为了做曲线对比也要截取掉\n",
    "#打包9.1-9.5预测的是9.15日的价格\n",
    "\n",
    "\n",
    "#标准化是为了什么？不同特征之间的数值大小，要拉平，才能拟合出一个合适的模型权重\n",
    "#特征的空间向量 构造的是X 接下来构造y  y和X长度要是一样的\n",
    "mem_his_days = 10\n",
    "from collections import deque\n",
    "deq = deque(maxlen=mem_his_days)\n",
    "\n",
    "X = []\n",
    "for i in sca_X:\n",
    "    deq.append(list(i))\n",
    "    if len(deq)==mem_his_days:\n",
    "        X.append(list(deq))\n",
    "        \n",
    "X_lately = X[-pre_days:]\n",
    "X = X[:-pre_days]\n",
    "print(len(X))#每一个deq里有5个，X最后将其全部append了\n",
    "#print(X)\n",
    "print(len(X_lately))\n",
    "\n",
    "y = df['label'].values[mem_his_days-1:-pre_days]#TODO: -1有一点点疑惑，以后懂了再解决\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4479, 10, 5)\n",
      "(4479,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(X)\n",
    "y =np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#开始用tf进行预测了\n",
    "import tensorflow.keras as tf\n",
    "from tensorflow.keras.models import Sequential #引入神经网络中的层 dropout 删除一些值\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
    "model = Sequential()\n",
    "model.add(LSTM(10,input_shape=X.shape[1:],activation='relu',return_sequences=True))#1: 有点疑惑\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(10,activation='relu',return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(10,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "#10个神经单元 input_shape为X  等下会划分一下 防止过拟合，就删除一些神经元\n",
    "#可以构建一个全连接层，激活函数也是relu Dense \n",
    "#做编译，有三个，优化器，损失函数，评价函数\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='mse',\n",
    "             metrics=['mape'])\n",
    "\n",
    "\n",
    "#开始训练\n",
    "model.fit(X_train,y_train,batch_size=32,epochs=50,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4416174819080898304\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 指定只是用第三块GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num GPUs Available:  0\n",
      "WARNING:tensorflow:From C:\\Users\\TedLau\\AppData\\Local\\Temp\\ipykernel_40840\\3358678444.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf1\n",
    "print(\"Num GPUs Available: \", len(tf1.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num GPUs Available: \", len(tf1.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf1.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf1\n",
    "with tf1.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf1.Session() as sess:\n",
    "    print (sess.run(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.7.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Version: \" + tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3570505637.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [55]\u001B[1;36m\u001B[0m\n\u001B[1;33m    print(\"Num GPUs Available: \", len(tf1.config.experimental.list_physical_devices('GPU')))print(\"Num GPUs Available: \", len(tf1.config.experimental.list_physical_devices('GPU')))\u001B[0m\n\u001B[1;37m                                                                                            ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf1\n",
    "print(\"Num GPUs Available: \", len(tf1.config.experimental.list_physical_devices('GPU')))print(\"Num GPUs Available: \", len(tf1.config.experimental.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [46]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m     b \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mconstant([\u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m2.0\u001B[39m, \u001B[38;5;241m3.0\u001B[39m, \u001B[38;5;241m4.0\u001B[39m, \u001B[38;5;241m5.0\u001B[39m, \u001B[38;5;241m6.0\u001B[39m], shape\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m2\u001B[39m], name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m     c \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmatmul(a, b)\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mtf1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSession\u001B[49m() \u001B[38;5;28;01mas\u001B[39;00m sess:\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m (sess\u001B[38;5;241m.\u001B[39mrun(c))\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf1\n",
    "with tf1.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf1.Session() as sess:\n",
    "    print (sess.run(c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.7.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Version: \" + tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}